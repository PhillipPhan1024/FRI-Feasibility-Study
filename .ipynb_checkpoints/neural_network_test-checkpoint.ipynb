{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created by zayaan. going to test using a basic neural network for the stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#we want to create a neural network, so we need to import the keras library\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"500k.csv\" \n",
    "df = pd.read_csv(csv_file, sep=\",\")\n",
    "# individual photometry filters\n",
    "u = df['u']\n",
    "g = df['g']\n",
    "r = df['r']\n",
    "i = df['i']\n",
    "z = df['z']\n",
    "\n",
    "# color indices\n",
    "u_g = u - g\n",
    "g_r = g - r\n",
    "r_i = r - i\n",
    "i_z = i - z\n",
    "\n",
    "# u_g = u_g[:-19500]\n",
    "# g_r = g_r[:-19500]\n",
    "# r_i = r_i[:-19500]\n",
    "# i_z = i_z[:-19500]\n",
    "\n",
    "# Effective temperature of star\n",
    "temperature = df['Teff']\n",
    "\n",
    "metallicity = df['FeH']\n",
    "\n",
    "color_filters_df = pd.DataFrame()\n",
    "color_filters_df['u_g'] = u_g\n",
    "color_filters_df['g_r'] = g_r\n",
    "color_filters_df['r_i'] = r_i\n",
    "color_filters_df['i_z'] = i_z\n",
    "\n",
    "# Effective temperature of star\n",
    "color_filters_df['temperature'] = df['Teff']\n",
    "color_filters_df['metallicity'] = df['FeH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            u_g      g_r      r_i      i_z  temperature  metallicity\n",
      "274199  0.74974  0.27792  0.11534  0.01098         8388         0.78\n",
      "266948  1.26185  0.18076 -0.00239 -0.08943         8388         0.78\n",
      "13473   1.29980  0.11159 -0.10133 -0.11050         8388         0.78\n",
      "265899  1.18326  0.07160 -0.09517 -0.08719         8388         0.78\n",
      "13789   1.29981  0.14667 -0.02716 -0.05719         8388         0.78\n",
      "...         ...      ...      ...      ...          ...          ...\n",
      "310647  0.65794  0.29682  0.13021  0.03009         3690         0.05\n",
      "25071   1.84317  1.69793  0.69444  0.43985         3690         0.05\n",
      "272035  1.23492  0.60226  0.50272  0.36063         3690         0.05\n",
      "194409  2.03738  1.21585  0.70653 -0.08243         3690         0.05\n",
      "13339   1.51349  0.53067  0.16795 -0.22044         3690         0.05\n",
      "\n",
      "[381336 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# remove outliers by removing all data points that are outside 25th percentile - 75th percentile range\n",
    "dropped_rows = set()\n",
    "\n",
    "# TEMPERATURE OUTLIERS    \n",
    "Q1_temp = color_filters_df['temperature'].quantile(0.25)\n",
    "Q3_temp = color_filters_df['temperature'].quantile(0.75)\n",
    "IQR = Q3_temp - Q1_temp\n",
    "lower = Q1_temp - 1.5*IQR\n",
    "upper = Q3_temp + 1.5*IQR\n",
    "\n",
    "upper_array = np.where(color_filters_df['temperature']>=upper)[0]\n",
    "lower_array = np.where(color_filters_df['temperature']<=lower)[0]\n",
    "\n",
    "for element in upper_array:\n",
    "    dropped_rows.add(element)\n",
    "for element in lower_array:\n",
    "    dropped_rows.add(element)\n",
    "\n",
    "# U_G OUTLIERS\n",
    "Q1_temp = color_filters_df['u_g'].quantile(0.25)\n",
    "Q3_temp = color_filters_df['u_g'].quantile(0.75)\n",
    "IQR = Q3_temp - Q1_temp\n",
    "lower = Q1_temp - 1.5*IQR\n",
    "upper = Q3_temp + 1.5*IQR\n",
    "\n",
    "upper_array = np.where(color_filters_df['u_g']>=upper)[0]\n",
    "lower_array = np.where(color_filters_df['u_g']<=lower)[0]\n",
    "\n",
    "for element in upper_array:\n",
    "    dropped_rows.add(element)\n",
    "for element in lower_array:\n",
    "    dropped_rows.add(element)\n",
    "    \n",
    "# G_R OUTLIERS\n",
    "Q1_temp = color_filters_df['g_r'].quantile(0.25)\n",
    "Q3_temp = color_filters_df['g_r'].quantile(0.75)\n",
    "IQR = Q3_temp - Q1_temp\n",
    "lower = Q1_temp - 1.5*IQR\n",
    "upper = Q3_temp + 1.5*IQR\n",
    "\n",
    "upper_array = np.where(color_filters_df['g_r']>=upper)[0]\n",
    "lower_array = np.where(color_filters_df['g_r']<=lower)[0]\n",
    "\n",
    "for element in upper_array:\n",
    "    dropped_rows.add(element)\n",
    "for element in lower_array:\n",
    "    dropped_rows.add(element)\n",
    "    \n",
    "# R_I OUTLIERS\n",
    "Q1_temp = color_filters_df['r_i'].quantile(0.25)\n",
    "Q3_temp = color_filters_df['r_i'].quantile(0.75)\n",
    "IQR = Q3_temp - Q1_temp\n",
    "lower = Q1_temp - 1.5*IQR\n",
    "upper = Q3_temp + 1.5*IQR\n",
    "\n",
    "upper_array = np.where(color_filters_df['r_i']>=upper)[0]\n",
    "lower_array = np.where(color_filters_df['r_i']<=lower)[0]\n",
    "\n",
    "for element in upper_array:\n",
    "    dropped_rows.add(element)\n",
    "for element in lower_array:\n",
    "    dropped_rows.add(element) \n",
    "\n",
    "# I_Z OUTLIERS\n",
    "Q1_temp = color_filters_df['i_z'].quantile(0.25)\n",
    "Q3_temp = color_filters_df['i_z'].quantile(0.75)\n",
    "IQR = Q3_temp - Q1_temp\n",
    "lower = Q1_temp - 1.5*IQR\n",
    "upper = Q3_temp + 1.5*IQR\n",
    "\n",
    "upper_array = np.where(color_filters_df['i_z']>=upper)[0]\n",
    "lower_array = np.where(color_filters_df['i_z']<=lower)[0]\n",
    "\n",
    "for element in upper_array:\n",
    "    dropped_rows.add(element)\n",
    "for element in lower_array:\n",
    "    dropped_rows.add(element) \n",
    "\n",
    "color_filters_df.drop(dropped_rows, inplace=True)\n",
    "print(color_filters_df.sort_values(by=['temperature'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the input of the model is the color indices, and the output is the temperature.\n",
    "#lets perform this with a neural network\n",
    "#we need to split the data into training and testing data\n",
    "#we will use 80% of the data for training and 20% for testing\n",
    "#we will also shuffle the data to avoid any bias\n",
    "\n",
    "X = color_filters_df[['u_g', 'g_r', 'r_i', 'i_z', 'metallicity']].values\n",
    "# X = color_filters_df[['g_r', 'r_i']].values\n",
    "y = color_filters_df['temperature'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the each X vs y\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.subplot(1, 4, 1)\n",
    "# plt.scatter(X_train[:, 0], y_train, s=1, label='train')\n",
    "# plt.scatter(X_test[:, 0], y_test, s=1, label='test')\n",
    "# plt.xlabel('u_g')\n",
    "# plt.ylabel('temperature')\n",
    "# plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(5,)), #change input shape based on how many u using\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  #1 neuron output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7627/7627 [==============================] - 24s 3ms/step - loss: 2604913.2500 - mae: 962.0429 - val_loss: 360482.6250 - val_mae: 397.5859\n",
      "Epoch 2/300\n",
      "7627/7627 [==============================] - 23s 3ms/step - loss: 355627.1875 - mae: 393.0087 - val_loss: 359212.8438 - val_mae: 392.9196\n",
      "Epoch 3/300\n",
      "7627/7627 [==============================] - 26s 3ms/step - loss: 354967.1250 - mae: 391.9200 - val_loss: 359070.0000 - val_mae: 392.7793\n",
      "Epoch 4/300\n",
      "7627/7627 [==============================] - 26s 3ms/step - loss: 354559.4375 - mae: 391.4277 - val_loss: 359289.4688 - val_mae: 392.9871\n",
      "Epoch 5/300\n",
      "7627/7627 [==============================] - 23s 3ms/step - loss: 353956.5000 - mae: 390.9227 - val_loss: 357986.6250 - val_mae: 392.6692\n",
      "Epoch 6/300\n",
      "7627/7627 [==============================] - 24s 3ms/step - loss: 353139.2500 - mae: 390.1229 - val_loss: 356838.5312 - val_mae: 390.7567\n",
      "Epoch 7/300\n",
      "7627/7627 [==============================] - 22s 3ms/step - loss: 352355.9688 - mae: 389.9629 - val_loss: 358420.2500 - val_mae: 389.8367\n",
      "Epoch 8/300\n",
      "7627/7627 [==============================] - 21s 3ms/step - loss: 351462.8750 - mae: 389.3283 - val_loss: 356057.5625 - val_mae: 389.4764\n",
      "Epoch 9/300\n",
      "7627/7627 [==============================] - 24s 3ms/step - loss: 350352.7188 - mae: 388.8089 - val_loss: 355791.1875 - val_mae: 386.8098\n",
      "Epoch 10/300\n",
      "7627/7627 [==============================] - 23s 3ms/step - loss: 347235.1875 - mae: 387.4511 - val_loss: 349916.9688 - val_mae: 387.7275\n",
      "Epoch 11/300\n",
      "7627/7627 [==============================] - 24s 3ms/step - loss: 344685.9375 - mae: 386.4010 - val_loss: 352182.2500 - val_mae: 390.5005\n",
      "Epoch 12/300\n",
      "7627/7627 [==============================] - 18s 2ms/step - loss: 344051.6562 - mae: 385.5791 - val_loss: 349844.6875 - val_mae: 387.5590\n",
      "Epoch 13/300\n",
      "7627/7627 [==============================] - 19s 3ms/step - loss: 343611.0000 - mae: 385.1631 - val_loss: 349013.5625 - val_mae: 381.6394\n",
      "Epoch 14/300\n",
      "7627/7627 [==============================] - 19s 2ms/step - loss: 343253.8750 - mae: 384.0887 - val_loss: 349465.6250 - val_mae: 386.0771\n",
      "Epoch 15/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 343035.0625 - mae: 383.8888 - val_loss: 349385.5938 - val_mae: 380.6025\n",
      "Epoch 16/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 342807.3750 - mae: 383.2343 - val_loss: 348285.0312 - val_mae: 383.6940\n",
      "Epoch 17/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 342536.8125 - mae: 382.8248 - val_loss: 348865.8125 - val_mae: 386.7176\n",
      "Epoch 18/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 342513.1562 - mae: 382.8057 - val_loss: 347885.6250 - val_mae: 380.5176\n",
      "Epoch 19/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 342444.1562 - mae: 382.3352 - val_loss: 347502.9062 - val_mae: 385.9364\n",
      "Epoch 20/300\n",
      "7627/7627 [==============================] - 18s 2ms/step - loss: 342387.9688 - mae: 382.3897 - val_loss: 347774.4688 - val_mae: 387.4105\n",
      "Epoch 21/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 342189.8438 - mae: 382.1569 - val_loss: 347210.6250 - val_mae: 383.0474\n",
      "Epoch 22/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 342064.4062 - mae: 382.0582 - val_loss: 347428.0000 - val_mae: 380.1992\n",
      "Epoch 23/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 341975.5938 - mae: 381.7358 - val_loss: 347813.2188 - val_mae: 380.6964\n",
      "Epoch 24/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 341998.4062 - mae: 381.5696 - val_loss: 349678.5000 - val_mae: 383.5359\n",
      "Epoch 25/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 341800.2188 - mae: 381.2483 - val_loss: 347696.7500 - val_mae: 387.0296\n",
      "Epoch 26/300\n",
      "7627/7627 [==============================] - 18s 2ms/step - loss: 341885.4062 - mae: 381.5510 - val_loss: 348043.0000 - val_mae: 380.6127\n",
      "Epoch 27/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 341805.1250 - mae: 381.1815 - val_loss: 348744.5000 - val_mae: 386.3800\n",
      "Epoch 28/300\n",
      "7627/7627 [==============================] - 17s 2ms/step - loss: 341738.2500 - mae: 381.0950 - val_loss: 346968.4375 - val_mae: 385.4082\n",
      "Epoch 29/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 341642.2812 - mae: 381.2194 - val_loss: 348337.6250 - val_mae: 381.5314\n",
      "Epoch 30/300\n",
      "7627/7627 [==============================] - 16s 2ms/step - loss: 341740.6875 - mae: 380.9861 - val_loss: 347556.6875 - val_mae: 385.4307\n",
      "Epoch 31/300\n",
      "6183/7627 [=======================>......] - ETA: 2s - loss: 340486.1562 - mae: 380.1782"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print accuracy of model\n",
    "print(model.evaluate(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "#assign max to a really low number\n",
    "max = -10000000\n",
    "#assign min to a really high number\n",
    "min = 10000000\n",
    "\n",
    "avg = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Input:\", X_test[i])\n",
    "    print(\"Expected Output:\", y_test[i])\n",
    "    print(\"Actual Output:\", predictions[i][0])  # predictions[i] is a 2D array, so we access the value with [0]\n",
    "    print()\n",
    "    #update max and min accordingly, based on difference in expected and actual output\n",
    "    if abs(y_test[i] - predictions[i][0]) > max:\n",
    "        max = abs(y_test[i] - predictions[i][0])\n",
    "    if abs(y_test[i] - predictions[i][0]) < min:\n",
    "        min = abs(y_test[i] - predictions[i][0])\n",
    "    avg += abs(y_test[i] - predictions[i][0])\n",
    "avg = avg / len(X_test)\n",
    "print(min, max, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
